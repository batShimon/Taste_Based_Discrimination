{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9255fb",
   "metadata": {},
   "source": [
    "**Author:** Revekka Gersgovich\n",
    "\n",
    "**Purpose:** Clean and merge the GSS Data downloaded from GSS website: https://gss.norc.org/get-the-data/stata.html \n",
    "\n",
    "**Date:** Nov 29, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bced843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import narwhals\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.abspath(\"/Users/revekkagershovich/Documents/Filling_system/Academic/Taste-Based_Discrimination\") # Change this directory to run from your computer\n",
    "assert os.path.exists(parent_dir), \"parent_dir does not exist\"\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "raw_data_dir = path.join(parent_dir, \"1_data\", \"1_raw\")\n",
    "assert os.path.exists(raw_data_dir), \"raw_data_dir does not exist\"\n",
    "\n",
    "intermediate_data_dir = path.join(parent_dir, \"1_data\", \"2_intermediate\")\n",
    "assert os.path.exists(intermediate_data_dir), \"intermediate_data_dir does not exist\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1374687",
   "metadata": {},
   "source": [
    "# Loading Datasets & Saving Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5b4c5",
   "metadata": {},
   "source": [
    "The data was downloaded from GSS Website: https://gss.norc.org/get-the-data/stata.html\n",
    "\n",
    "It was manually extracted from Zip files prior to loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00e8d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1996\n",
    "df_1996, meta_1996 = pyreadstat.read_dta(\n",
    "    os.path.join(raw_data_dir, \"GSS1996.dta\"),\n",
    "    apply_value_formats=False  # keep numeric codes, don't turn into labels\n",
    ")\n",
    "\n",
    "# 2002\n",
    "df_2002, meta_2002 = pyreadstat.read_dta(\n",
    "    os.path.join(raw_data_dir, \"GSS2002.dta\"),\n",
    "    apply_value_formats=False\n",
    ")\n",
    "\n",
    "# 2006\n",
    "df_2006, meta_2006 = pyreadstat.read_dta(\n",
    "    os.path.join(raw_data_dir, \"GSS2006.dta\"),\n",
    "    apply_value_formats=False\n",
    ")\n",
    "\n",
    "# 2018\n",
    "df_2018, meta_2018 = pyreadstat.read_dta(\n",
    "    os.path.join(raw_data_dir, \"GSS2018.dta\"),\n",
    "    apply_value_formats=False\n",
    ")\n",
    "\n",
    "# 2024 (inside subfolder)\n",
    "df_2024, meta_2024 = pyreadstat.read_dta(\n",
    "    os.path.join(raw_data_dir, \"2024\", \"GSS2024.dta\"),\n",
    "    apply_value_formats=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b18102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metadata_to_csv(meta, year):\n",
    "    labels_df = pd.DataFrame({\n",
    "        \"variable\": meta.column_names,\n",
    "        \"label\": meta.column_labels\n",
    "    })\n",
    "    labels_df.to_csv(os.path.join(raw_data_dir, f\"GSS_{year}_variable_labels.csv\"), index=False)\n",
    "\n",
    "save_metadata_to_csv(meta_1996, 1996)\n",
    "save_metadata_to_csv(meta_2002, 2002)\n",
    "save_metadata_to_csv(meta_2006, 2006)\n",
    "save_metadata_to_csv(meta_2018, 2018)\n",
    "save_metadata_to_csv(meta_2024, 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd9351",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1996.shape, df_2002.shape,df_2006.shape, df_2018.shape, df_2024.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a30efb",
   "metadata": {},
   "source": [
    "# Merging Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdb825d",
   "metadata": {},
   "source": [
    "## Check variable consistency across years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_1996 = set(df_1996.columns)\n",
    "set_2002 = set(df_2002.columns)\n",
    "set_2006 = set(df_2006.columns)\n",
    "set_2018 = set(df_2018.columns)\n",
    "set_2024 = set(df_2024.columns)\n",
    "\n",
    "datasets = {\n",
    "    \"1996\": set_1996,\n",
    "    \"2002\": set_2002,\n",
    "    \"2006\": set_2006,\n",
    "    \"2018\": set_2018,\n",
    "    \"2024\": set_2024\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of years with adult mental health stigma module, and years with child mental health stigma module\n",
    "adult_years = [\"1996\", \"2006\", \"2018\", \"2024\"]\n",
    "child_years = [\"2002\", \"2024\"]\n",
    "\n",
    "# Adult stigma variables: common to 1996, 2006, 2018, 2024\n",
    "adult_stigma_vars = set.intersection(*(datasets[year] for year in adult_years))\n",
    "\n",
    "# Child stigma variables: common to 2002 and 2024\n",
    "child_stigma_vars = set.intersection(*(datasets[year] for year in child_years))\n",
    "\n",
    "# Respondent mental health variables in various years\n",
    "mh_vars = [\n",
    "    \"evbrkdwn\",   # ever felt like having a nervous breakdown\n",
    "    \"relmhsp1\",   # patient was self (mental health help-seeking)\n",
    "    \"evmhp\",      # ever had a mental health problem\n",
    "    \"mntlhlth\",   # days of poor mental health, past 30 days\n",
    "    \"govmentl\",   # attitudes about government and mental health\n",
    "    \"depress\",    # ever told by a doctor you had depression\n",
    "    \"diagnosd\",   # ever diagnosed with mental health problem\n",
    "    \"mhtreatd\",   # ever treated for mental health problem\n",
    "    \"emoprobs\"    # emotional problems interfering with life\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Union of all variables you care about\n",
    "keep_vars = adult_stigma_vars | child_stigma_vars | set(mh_vars)\n",
    "\n",
    "# (Optional but very useful): also keep 'year' if it exists\n",
    "keep_vars_with_year = set(keep_vars) | {\"year\"}\n",
    "\n",
    "# 2. Helper to subset a df safely\n",
    "def subset_wave(df, year_label):\n",
    "    cols_in_df = set(df.columns)\n",
    "    cols_to_keep = list(keep_vars_with_year & cols_in_df)\n",
    "\n",
    "    tmp = df[cols_to_keep].copy()\n",
    "\n",
    "    # Ensure a proper 'year' column exists\n",
    "    if \"year\" not in tmp.columns:\n",
    "        tmp[\"year\"] = int(year_label)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "# 3. Apply to each wave\n",
    "df_1996_sub = subset_wave(df_1996, 1996)\n",
    "df_2002_sub = subset_wave(df_2002, 2002)\n",
    "df_2006_sub = subset_wave(df_2006, 2006)\n",
    "df_2018_sub = subset_wave(df_2018, 2018)\n",
    "df_2024_sub = subset_wave(df_2024, 2024)\n",
    "\n",
    "# 4. Concatenate all waves into a single dataset\n",
    "df = pd.concat(\n",
    "    [df_1996_sub, df_2002_sub, df_2006_sub, df_2018_sub, df_2024_sub],\n",
    "    ignore_index=True,\n",
    "    sort=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c994db9",
   "metadata": {},
   "source": [
    "# Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc829d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06449261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bad75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1ee07",
   "metadata": {},
   "source": [
    "# Saving Datasets and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db01cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put metadata objects into a dict for iteration\n",
    "meta_dict = {\n",
    "    \"1996\": meta_1996,\n",
    "    \"2002\": meta_2002,\n",
    "    \"2006\": meta_2006,\n",
    "    \"2018\": meta_2018,\n",
    "    \"2024\": meta_2024\n",
    "}\n",
    "\n",
    "# Start the unified codebook using *all* variables from the final df\n",
    "unified_vars = set(df.columns)\n",
    "unified_codebook = pd.DataFrame({\"variable\": sorted(unified_vars)})\n",
    "\n",
    "# For each year, merge in that year's labels\n",
    "for year, meta in meta_dict.items():\n",
    "    year_cb = pd.DataFrame({\n",
    "        \"variable\": meta.column_names,\n",
    "        f\"label_{year}\": meta.column_labels\n",
    "    })\n",
    "    unified_codebook = unified_codebook.merge(year_cb, on=\"variable\", how=\"left\")\n",
    "\n",
    "# Add a convenience column showing all years where the variable appears\n",
    "def list_years_present(row):\n",
    "    present = [year for year in meta_dict.keys()\n",
    "               if pd.notna(row[f\"label_{year}\"])]\n",
    "    return \", \".join(present)\n",
    "\n",
    "unified_codebook[\"years_present\"] = unified_codebook.apply(list_years_present, axis=1)\n",
    "\n",
    "# Save it\n",
    "unified_codebook.to_csv(\n",
    "    os.path.join(intermediate_data_dir, \"codebook.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77405cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_codebook.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477bd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "unified_codebook['years_present'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb07194",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_child_codebook = unified_codebook[unified_codebook['years_present'] ==  \"2002, 2024\"]\n",
    "mh_child_codebook\n",
    "mh_child_codebook.to_csv(\n",
    "    os.path.join(intermediate_data_dir, \"mh_child_codebook.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a31b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mh_adult_codebook = unified_codebook[unified_codebook['years_present'] ==  \"1996, 2006, 2018, 2024\"]\n",
    "mh_adult_codebook\n",
    "\n",
    "mh_adult_codebook.to_csv(\n",
    "    os.path.join(intermediate_data_dir, \"mh_adult_codebook.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac269e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(intermediate_data_dir, \"gss_cleaned_96_02_06_18_24.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Revekka_first_environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
